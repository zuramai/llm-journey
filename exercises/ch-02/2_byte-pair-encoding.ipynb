{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1fa0760b-04e8-4442-92cd-d1e65083ff93",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: tiktoken in /Users/zuramai/Code/LLM/llm-journey/.venv/lib/python3.10/site-packages (0.9.0)\n",
      "Requirement already satisfied: regex>=2022.1.18 in /Users/zuramai/Code/LLM/llm-journey/.venv/lib/python3.10/site-packages (from tiktoken) (2024.11.6)\n",
      "Requirement already satisfied: requests>=2.26.0 in /Users/zuramai/Code/LLM/llm-journey/.venv/lib/python3.10/site-packages (from tiktoken) (2.32.3)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /Users/zuramai/Code/LLM/llm-journey/.venv/lib/python3.10/site-packages (from requests>=2.26.0->tiktoken) (3.4.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/zuramai/Code/LLM/llm-journey/.venv/lib/python3.10/site-packages (from requests>=2.26.0->tiktoken) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/zuramai/Code/LLM/llm-journey/.venv/lib/python3.10/site-packages (from requests>=2.26.0->tiktoken) (2.3.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/zuramai/Code/LLM/llm-journey/.venv/lib/python3.10/site-packages (from requests>=2.26.0->tiktoken) (2025.1.31)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install tiktoken"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "96e2235c-a808-4081-aa13-746c8e40690f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tiktoken version:  0.9.0\n"
     ]
    }
   ],
   "source": [
    "# Check tiktoken version\n",
    "from importlib.metadata import version\n",
    "import tiktoken\n",
    "print(\"tiktoken version: \", version(\"tiktoken\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8b348d93-55e0-4565-a02f-177b48e5cdce",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = tiktoken.get_encoding(\"gpt2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fbcc6557-60a7-44e4-b422-1f8c5c8d52e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[15496, 11, 466, 345, 588, 8887, 30, 220, 50256, 554, 262, 4252, 18250, 8812, 2114, 286, 617, 34680, 27271]\n"
     ]
    }
   ],
   "source": [
    "text = (\"Hello, do you like tea? <|endoftext|> In the sunlit terraces of someunknownPlace\")\n",
    "integers = tokenizer.encode(text, allowed_special={\"<|endoftext|>\"})\n",
    "print(integers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5cf485ae-d46a-456e-8423-165a0bb43a3f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hello, do you like tea? <|endoftext|> In the sunlit terraces of someunknownPlace\n"
     ]
    }
   ],
   "source": [
    "# it can decode the unknown words!\n",
    "strings = tokenizer.decode(integers)\n",
    "print(strings)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ff18d61-8596-4cba-8c8d-a1c7b27d99bd",
   "metadata": {},
   "source": [
    "Now we read all of the \"the-verdict.txt\" "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f424718f-66e0-47bd-ba43-57f7e107d0d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5145\n"
     ]
    }
   ],
   "source": [
    "with open(\"the-verdict.txt\", \"r\", encoding=\"utf-8\") as f:\n",
    "    raw_text = f.read()\n",
    "enc_text = tokenizer.encode(raw_text)\n",
    "print(len(enc_text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "47233685-32b7-4793-881f-b02052de67be",
   "metadata": {},
   "outputs": [],
   "source": [
    "enc_sample = enc_text[:50]\n",
    "context_size = 4 # determines how many tokens included in the input\n",
    "x = enc_sample[:context_size]\n",
    "y = enc_sample[1:context_size+1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "100f50b1-8ce4-4714-8867-22b2ebcee2ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I --->  H\n",
      "I H ---> AD\n",
      "I HAD --->  always\n",
      "I HAD always --->  thought\n"
     ]
    }
   ],
   "source": [
    "for i in range(1, context_size+1):\n",
    "    context = enc_sample[:i]\n",
    "    desired = enc_sample[i:i+1]\n",
    "    print(tokenizer.decode(context), \"--->\", tokenizer.decode(desired))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ae3c189-c6fd-47f4-95c4-8cd35cfdf82d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
