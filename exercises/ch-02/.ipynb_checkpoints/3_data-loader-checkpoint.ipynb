{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "006e0879-87ac-472c-80dd-57ca10168e1d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "13f4759e-4199-41c8-a3bc-a90992f05a5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from gpt_loader import GPTDatasetV1 \n",
    "from torch.utils.data import DataLoader\n",
    "import tiktoken"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "fd01085b-804e-41df-9d9d-b0045239265b",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = tiktoken.get_encoding(\"gpt2\")\n",
    "def create_dataloader_v1(txt, batch_size=4, max_length=256, stride=128, shuffle=True, drop_last=True, num_workers=0):\n",
    "    dataset = GPTDatasetV1(txt, tokenizer, max_length, stride)\n",
    "    dataloader = DataLoader(\n",
    "        dataset,\n",
    "        batch_size=batch_size,\n",
    "        shuffle=shuffle,\n",
    "        drop_last=drop_last,\n",
    "        num_workers=num_workers\n",
    "    )\n",
    "    return dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "3811ce58-eefe-4c2f-871e-d577fa9a737f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[tensor([[   40,   367,  2885,  1464],\n",
      "        [ 1807,  3619,   402,   271],\n",
      "        [10899,  2138,   257,  7026],\n",
      "        [15632,   438,  2016,   257]]), tensor([[  367,  2885,  1464,  1807],\n",
      "        [ 3619,   402,   271, 10899],\n",
      "        [ 2138,   257,  7026, 15632],\n",
      "        [  438,  2016,   257,   922]])]\n",
      "I HAD always\n",
      " thought Jack Gis\n",
      "burn rather a cheap\n",
      " genius--though a\n",
      "\n",
      "\n",
      " HAD always thought\n",
      " Jack Gisburn\n",
      " rather a cheap genius\n",
      "--though a good\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "with open(\"the-verdict.txt\", \"r\", encoding=\"utf-8\") as f:\n",
    "    raw_text = f.read()\n",
    "batch_size = 4\n",
    "dataloader = create_dataloader_v1(raw_text, batch_size, max_length=4, stride=4, shuffle=False)\n",
    "data_iter = iter(dataloader)\n",
    "first_batch = next(data_iter)\n",
    "print(first_batch)\n",
    "for i in first_batch:\n",
    "    for batch in i:\n",
    "        print(tokenizer.decode(batch.flatten().tolist()))\n",
    "    print(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "80003d9a-caa9-441e-9b71-d1a972fd683c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AD always thought Jack Gisburn rather\n",
      " always thought Jack Gisburn rather a\n"
     ]
    }
   ],
   "source": [
    "second_batch = next(data_iter)\n",
    "for i in second_batch:\n",
    "    print(tokenizer.decode(i.flatten().tolist()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "7c49816d-5993-4c50-8e51-fe4db85e8773",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[15632, 438, 2016, 257]\n",
      "[438, 2016, 257, 922]\n"
     ]
    }
   ],
   "source": [
    "for i in second_batch:\n",
    "    print(i.flatten().tolist())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae2a5a49-14a0-4248-86e1-b0a85dc59824",
   "metadata": {},
   "source": [
    "## Creating token embeddings\n",
    "We will create an example of input_ids of `[2, 3, 5, 1]` and create an embedding layer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "23b59b5c-5b19-41d7-9cb8-e62ab4ea4555",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "# For example, we create a input_ids with four input token\n",
    "input_ids = torch.tensor([2, 3, 5, 1])\n",
    "# and we have vocab size of 6 and output dimensions 3\n",
    "vocab_size = 6\n",
    "output_dim = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "e394c5cf-a6a4-4e89-a6a6-b9bac0800a1d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameter containing:\n",
      "tensor([[ 0.3374, -0.1778, -0.1690],\n",
      "        [ 0.9178,  1.5810,  1.3010],\n",
      "        [ 1.2753, -0.2010, -0.1606],\n",
      "        [-0.4015,  0.9666, -1.1481],\n",
      "        [-1.1589,  0.3255, -0.6315],\n",
      "        [-2.8400, -0.7849, -1.4096]], requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "# for reproducibility purpose\n",
    "torch.manual_seed(123)\n",
    "\n",
    "#create the embedding layer\n",
    "embedding_layer = torch.nn.Embedding(vocab_size, output_dim)\n",
    "print(embedding_layer.weight)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "ddd4c1ff-d96f-4743-b2f1-9d2a8e269e3a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-0.4015,  0.9666, -1.1481]], grad_fn=<EmbeddingBackward0>)\n"
     ]
    }
   ],
   "source": [
    "# try getting the embedding layer at row [3]\n",
    "print(embedding_layer(torch.tensor([3])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "4c976474-09fe-4302-8691-256157bb5875",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 1.2753, -0.2010, -0.1606],\n",
      "        [-0.4015,  0.9666, -1.1481],\n",
      "        [-2.8400, -0.7849, -1.4096],\n",
      "        [ 0.9178,  1.5810,  1.3010]], grad_fn=<EmbeddingBackward0>)\n"
     ]
    }
   ],
   "source": [
    "# try getting the embeddings from input_ids\n",
    "print(embedding_layer(input_ids))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39bb9bf8-25d7-424f-840c-fa4d02992eb6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
